{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Nodos Documentation","text":"<p>Welcome to the official documentation for Nodos, an advanced node-based graph scheduling system.</p> <p>Use the navigation on the left to browse through the different sections of the documentation.</p>"},{"location":"HowToWriteDocs/","title":"How To Write Docs","text":"<p>Nodos documentation is written using markdown syntax and we use MkDocs and Material theme for now. If you want to contribute or extend Nodos documentation, you can follow these steps:</p> <pre><code>git clone https://github.com/mediaz/docs.git\npip install mkdocs\npip install mkdocs-material\n</code></pre> <p>To start serving locally from http://127.0.0.1:8000/ <pre><code>mkdocs serve\n</code></pre> Then you should create a pull request for your commit in our documentation.</p>"},{"location":"contributing/","title":"Contributing Guidelines","text":"<p>We encourage users to read the source code of our modules to understand the underlying mechanisms. If you find a bug or have suggestions for improvements, please contribute by submitting a pull request with your proposed fix.</p> <p>To contribute:</p> <ol> <li>Clone the Repository: Clone the official Nodos repository to your local machine.</li> <li>Create a Branch: Develop your fix or feature in a new branch.</li> <li>Submit a Pull Request: Once your changes are complete, submit a pull request for review.</li> </ol> <p>Please refer to the contributing guidelines in the repository for more details.</p>"},{"location":"features/","title":"Key Features","text":"<ul> <li>Node-Based Graph Scheduling: Nodos leverages a dynamic node-based graph structure, offering flexible and efficient scheduling for various tasks and processes.</li> <li>C++ Development: Nodes are developed using C++, ensuring high performance and robustness.</li> <li>C API Support: The system supports node creation via a C API, making it accessible to a broader range of developers.</li> <li>Shader Language Integration: Supports GLSL and HLSL shaders, with automatic compilation and runtime linking to shader parameters, eliminating the need for additional C++ code. Both fragment and computer shaders are supported.</li> <li>Cross-Process AppSDK: Enables seamless execution of another process, linked with Nodos process within the node graph using the Nodos AppSDK.</li> <li>AI Model Support with ONNX Runtime: Run AI models in real-time using ONNX Runtime with CUDA and TensorRT, supporting image-to-image models including segmentation, super resolution, and depth generation.</li> </ul>"},{"location":"installation/","title":"Installation Instructions","text":"<p>Info</p> <p>We distribute Nodos with a .zip file, since we don't need any admin rights or do not need to install under Program Files folder.</p>"},{"location":"installation/#without-any-compilation","title":"Without any Compilation","text":"<ol> <li> <p>Download the .zip File: Download latest Nodos build from our Github: (https://github.com/mediaz/nodos-index/releases?q=nodos&amp;expanded=true)</p> </li> <li> <p>Extract the .zip File: Unzip the downloaded file to your desired directory.</p> <p></p> </li> <li> <p>Double click on <code>nosman.exe</code> and this will both run the distributed Nodos and its Editor GUI.</p> <p>Info</p> <p>Normally <code>nosman.exe</code> is the command line interface to manage Nodos. But if you run it form explorer, it will try to be user friendly and tries to run Nodos easily for you.</p> </li> </ol>"},{"location":"installation/#developing-nodes-with-c","title":"Developing Nodes with C++","text":"<ol> <li>Set Up Environment: Ensure your development environment is configured with a C++ compiler and shader compilation tools.</li> <li>Install Dependencies with nosman:<ul> <li>Open a terminal or command prompt in the Nodos directory.</li> <li>Run <code>nosman install</code> to handle any subsystem and dependency installation.</li> </ul> </li> <li>Verify Installation: Open a terminal or command prompt and run <code>nosman --version</code> to verify the installation.</li> </ol> <p>Info</p> <p>Just type <code>nosman</code> from command line to get help: </p>"},{"location":"introduction/","title":"Introduction","text":"<p>Nodos is an advanced node-based graph scheduling system that is designed to simplify and streamline the development process. The name \"Nodos\" humorously plays on the idea that it is \"not DOS,\" referencing the classic MS-DOS, while also emphasizing its core functionality as a node-oriented system.</p> <p></p> <p>Developed in C++, Nodos provides robust support for node creation using a C API. Additionally, it integrates seamlessly with shader languages such as GLSL and HLSL, enabling the compilation and runtime linking of shaders to shader parameters without the need for additional programming. This unique capability allows developers to execute C++ code and shaders within the node graph effortlessly, enhancing productivity and flexibility.</p> <p>Nodos also allows you to connect from another process to the Nodos process via cross-platform communication using the app SDK we provide. This means that even your external processes can be represented as nodes inside Nodos, enabling us to schedule and manage these processes within our comprehensive \"Uber\" node graph.</p>"},{"location":"introduction/#key-benefits","title":"Key Benefits","text":"<ul> <li>Simplified Development: By leveraging node-based graph scheduling, Nodos simplifies the complexity of managing various tasks and processes.</li> <li>Performance and Flexibility: C++ development ensures high performance, while the C API support and shader integration offer flexibility for a wide range of applications.</li> <li>Shader Integration: Automatic handling of shader compilation and runtime linking allows for seamless execution of graphical applications without additional C++ coding.</li> <li>Cross Process Communication: Nodos allows you to connect from another process to the Nodos process via a cross-platform communication mechanism using the provided app SDK. This enables even external processes to be presented as nodes within Nodos.</li> <li>Uber Node Graph: With the ability to integrate external processes as nodes, Nodos can schedule and manage these processes within its comprehensive node graph, creating an \"Uber\" node graph that encompasses a wide array of tasks and operations.</li> </ul>"},{"location":"introduction/#example-applications","title":"Example Applications","text":"<p>Nodos provides example applications to demonstrate cross-process communication:</p> <ul> <li>Vulkan Application: Demonstrates high-performance graphics integration using the Vulkan Graphics API.</li> <li> <p>DirectX 12 Application: Demonstrates high-performance graphics integration using DirectX Graphics API.</p> </li> <li> <p>Unreal Engine 5 Integration: Nodos currently supports cross-process communication infrastructure for Unreal Engine 5. We provide an Unreal Engine 5 plugin named Nodos Link: github.com/mediaz/ue5plugin, available in our GitHub workspace. The source code for this plugin is publicly accessible, allowing developers to integrate and extend their Unreal Engine projects with Nodos seamlessly.</p> </li> </ul>"},{"location":"introduction/#use-cases","title":"Use Cases","text":"<p>Nodos can be utilized in various domains, including but not limited to:</p> <ul> <li>Real-Time Rendering: Using Vulkan, rendering nodes and image filters or compute shader nodes can be developed.</li> <li>Real-Time AI Processing With AI subsystem, ONNX models can be loaded and run in real-time, to process images/video. Such as segmentation, detection, depth generation, super resolution etc...</li> <li>Distributed Systems: Facilitates the integration and management of distributed processes, presenting them as nodes in a unified graph. Since Nodos provides a lot of capabilities in terms of video I/O, rendering, image filters and AI capabilities; your application can benefit from all these capabilities via just getting linked with Nodos AppSDK.</li> </ul>"},{"location":"license/","title":"License","text":"<p>Nodos is distributed under a custom license that is very permissive, even for commercial use. For detailed information, please refer to the LICENSE file included with the distribution.</p>"},{"location":"requirements/","title":"System Requirements","text":"<ul> <li>Operating System: Windows 10 or later</li> <li>GPU: The GPU driver should be supporting Vulkan 1.2 specs.</li> <li>Development Environment: C++ compiler (e.g., MSVC), Shader compiler (for GLSL/HLSL)</li> <li>Dependencies: Standard C++ libraries, Shader compilation tools</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<ul> <li>Discord Server: Join the Nodos community Discord Server for support from other users and developers.</li> </ul>"},{"location":"usage/","title":"Usage Instructions","text":"<ol> <li>Creating Nodes: Develop your nodes using C++ or the C API. Refer to the API documentation for detailed instructions.</li> <li>Integrating Shaders: Write your shaders in GLSL or HLSL. Nodos will handle the compilation and runtime linking automatically.</li> <li>Building the Node Graph: Use the Nodos interface to connect and configure your nodes, creating the desired graph structure.</li> <li>Running the Graph: Execute the node graph within Nodos to see your code and shaders in action.</li> </ol>"},{"location":"usage/#running-ai-models","title":"Running AI Models","text":"<p>Nodos support both AI Model inference and optimization with TensorRT.  One could use AIModelLoader node, which can be found in ML-&gt;AI Models-&gt;AI MOdel Loader in the context menu with the right click. This node required the Model Path, which is path to any ONNX Model (with ONNXRuntime 1.16 supports).  </p> <p>For ONNXRunLocation, we suggest using TensorRT and enabling FP16 Optimization in general, but some models may not be suitable for TensorRT. In that case, model load will fail and you get the corresponding error log in the Log pane for the reasons of fail.</p> <p>Note that optimization may take some time, and for the AI Models with dynamic input/output (models where any dimension of the i/o tensors is -1), the optimization will be performed during the output tensor determination. In other words, when you first conenct an input to the model. During that time the node status message \"Determining Output Tensor Info...\" will be displayed.</p> <p>For more advanced and performant applications, the Stream pin would come handy; this provides full GPU async operation of the AI Model Inference pipeline for that specific stream. But you must set the Stream pin before clicking to \"LoadModel\" button.</p> <p>After loading the model, we can connect the Model pin to the ONNXRunner node to see the I/O information of the model.</p> <p></p> <p>In above figure one can observe that the loaded model has the Input Tensor called \"image\" with the shape (1, 3, -1, -1) and Output Tensor called \"depth\" with the dimensions (-1, 1, -1, -1).</p> <p>In general, the Output Tensor strictly depends on the Input Tensor and it will be determined when the Input Tensor set.</p> <p>Now lets discuss how we can create the image tensor within Nodos features.</p>"},{"location":"usage/#texture-tensor-transformations","title":"Texture-Tensor Transformations","text":"<p>It is well known that TensorRT and CUDA are not compatible with Vulkan data by nature, but in Nodos this is not problem thanks to our Texture-to-Tensor and Tensor-to-Texture nodes.</p> <p>Users first must understand the nature of their tensor requested by the AI Model, this information is hidden in the \"element_type\" field of the Tensor Pins.</p> <p></p> <p>In the Figure above we see that the element type of the image tensor is \"float\", which corresponds to 32 bit per elements. So, we must ensure that the texture we want to use for our model is compatible with this data format. To do that, one can either use a texture with R32G32B32A32_SFLOAT type or make use of another handy Nodos feature: Texture Format Converter Node.</p> <p>First, lets create a Texture Format Converter Node and select the OutputFormat parameter as R32G32B32A32_SFLOAT.</p> <p></p> <p>Then create TextureToTensor node and connect the TextureFormatConverter's output to the TextureToTensor's input.</p> <p></p> <p>Now remember that the \"image\" input of the our AI Model was requesting a tensor with shape (1, 3, -1, -1), this also known as NCHW layout where the 1st dimension corresponds to Batch, 2nd dimension corresponds to Channel, 3rd dimension is Height and 4th dimension is Width.</p> <p>And also observe that our TextureToTensor node has NHWC Layout. Now lets change that to NCHW and also since our model requires 3 channel image also change the Output Format parameter of TextureToTensor to RGB from RGBA.</p> <p></p> <p>Observe that now the OutputTensor has the shape (1,3,1080,1920) and this shape is compatible with our AI Model's input.</p> <p>Now we can begin the TensorRT optimization (since we have dynamic input model) by connecting this tensor to our model.</p> <p></p> <p>After these steps, now we can connect the \"depth\" pin of our AI Model to TensorToTexture node with similar adjustments: choose the NCHW layout and since our output image has only one channel enable \"EnforceFourChannelOutput\".</p> <p></p> <p>Congratulations, now you can run any image-to-image AI model by following the same pipeline creation steps.</p>"},{"location":"usage/#useful-features","title":"Useful Features","text":"<p>If you are a curious about the GPU run time of your model, in the ONNXRunner Node properties you simply can enable \"Measure Time\" to see how long it takes for your model to run in GPU, you can open the Watch pane and read the ONNX Runner Elapsed Time and ONNX Runner AVG Elapsed Time fields (note that the values are in microseconds).</p> <p></p>"},{"location":"Subsystems/nosVulkan/","title":"nosVulkan Subsystem","text":"<p>nosVulkan subsystem features an API for plugins to communicate with vulkan &amp; send commands to the GPU.</p>"},{"location":"Subsystems/nosVulkan/#minimal-example","title":"Minimal example","text":"<p>For a plugin or a subsystem, to define a dependency to nosVulkan, add the nosVulkan dependency in the noscfg file as shown in <code>Test.noscfg</code>. Then in the file that contains the <code>MZ_INIT</code> macro, include <code>&lt;nosVulkanSubsystem/nosVulkanSubsystem.h&gt;</code> for nosVulkan API, then in the <code>nosExportNodeFunctions</code> function request the nosVulkan subsystem using <code>nosEngine.RequestSubsystem</code> function. Then <code>nosVulkan</code> global variable can be used anywhere to communicate with the nosVulkan API. <code>&lt;nosVulkanSubsystem/Helpers.hpp&gt;</code> contains helper functions and <code>&lt;nosVulkanSubsystem/Types_generated.h&gt;</code> contains flatbuffers headers for Texture.</p> Test.noscfg<pre><code>{\n    \"info\": {\n        \"id\": {\n            \"name\": \"nos.test\",\n            \"version\": \"1.0.0\"\n        },\n        \"display_name\": \"Test\",\n        \"description\": \"Test plugin.\",\n        \"dependencies\": [\n            {\n                \"name\": \"nos.sys.vulkan\",\n                \"version\": \"1.0.0\"\n            }\n        ]\n    },\n    \"node_definitions\":...\n}\n</code></pre> Test.cpp<pre><code>#include &lt;Nodos/PluginAPI.h&gt;\n\n#include &lt;nosVulkanSubsystem/nosVulkanSubsystem.h&gt;\n#include &lt;nosVulkanSubsystem/Helpers.hpp&gt;\n\nNOS_INIT();\nnosVulkanSubsystem* nosVulkan = nullptr;//nosVulkan is a variable that is declared as extern in nosVulkanSubsystem.h\nextern \"C\"\n{\n\n    NOSAPI_ATTR nosResult NOSAPI_CALL nosExportNodeFunctions(size_t* outCount, nosNodeFunctions** outFunctions)\n    {\n        *outCount = (size_t)(1);\n        if (!outFunctions)\n            return NOS_RESULT_SUCCESS;\n        auto ret = nosEngine.RequestSubsystem(NOS_NAME_STATIC(NOS_VULKAN_SUBSYSTEM_NAME), 1, 0, (void**)&amp;nosVulkan);\n        //System might not have nosVulkanSubsystem with the requested version, so be sure to check for it.\n        if (ret != NOS_RESULT_SUCCESS)\n            return ret;\n        //Register nodes etc...\n        outFunctions[0]-&gt;ClassName = NOS_NAME_STATIC(\"nos.test.CopyTestLicensed\");\n        outFunctions[0]-&gt;ExecuteNode = [](void* ctx, const nosNodeExecuteArgs* args)\n        {\n            nosCmd cmd;\n            nosVulkan-&gt;Begin(\"(nos.test.CopyTest) Copy\", &amp;cmd);\n            auto values = nos::GetPinValues(args);\n            nosResourceShareInfo input = nos::vkss::DeserializeTextureInfo(values[NOS_NAME_STATIC(\"Input\")]);\n            nosResourceShareInfo output = nos::vkss::DeserializeTextureInfo(values[NOS_NAME_STATIC(\"Output\")]);\n            nosVulkan-&gt;Copy(cmd, &amp;input, &amp;output, 0);\n            nosVulkan-&gt;End(cmd, NOS_FALSE);\n            return NOS_RESULT_SUCCESS;\n        };\n        return NOS_RESULT_SUCCESS;\n    }\n}\n</code></pre> <p>Warning</p> <p>Don't forget to check for the availability of the subsystem. Since the subsystem may not be available.</p>"},{"location":"Subsystems/nosVulkan/#shader-only-nodes","title":"Shader Only Nodes","text":"<p>To add a shader only node(such as <code>Color Correct</code>), add the node to plugin's noscfg and create a nosdef for the node. In the nosdef, add pins and other fields as if the node is a regular node. Then, in the node definition, fill the <code>\"contents</code> field as shown in the example. The path given in <code>shader</code> field is relative to the plugin's noscfg file. If the file extension doesn't end with <code>.spv</code>, nosVulkan tries to compile the given file using glslc and dxc, whichever compiles. Shader only nodes do not need a .dll file and the plugin doesn't need to export their node functions. <pre><code>{\n    \"nodes\": [\n        {\n            \"class_name\": \"ColorCorrect\",\n            \"contents_type\": \"Job\",\n            \"contents\": {\n                \"type\": \"nos.sys.vulkan.GPUNode\",\n                \"options\": {\n                    \"shader\": \"../Shaders/ColorCorrect.hlsl\",\n                    \"stage\": \"FRAGMENT\"\n                }\n            },\n            \"pins\": ...\n        }\n    ]\n}\n</code></pre></p>"},{"location":"Subsystems/nosVulkan/#types","title":"Types","text":""},{"location":"Subsystems/nosVulkan/#nosresourcetype","title":"nosResourceType","text":"<p><pre><code>enum nosResourceType\n{\n    NOS_RESOURCE_TYPE_BUFFER = 1,\n    NOS_RESOURCE_TYPE_TEXTURE = 2,\n}\n</code></pre> Refer to nosResourceShareInfo.</p>"},{"location":"Subsystems/nosVulkan/#nosresourceinfo","title":"nosResourceInfo","text":"<p><pre><code>struct nosResourceInfo\n{\n    nosResourceType Type;\n    union {\n        nosTextureInfo Texture;\n        nosBufferInfo Buffer;\n    };\n};\n</code></pre> <code>Type</code> must be set to adequate <code>nosResourceType</code> based on which resource info is used.</p>"},{"location":"Subsystems/nosVulkan/#functions","title":"Functions","text":"<p>Most operations in nosVulkan API uses a <code>nosCmd</code> struct to record commands and most calls are not synchronized between CPU and GPU.</p>"},{"location":"Subsystems/nosVulkan/#begin","title":"Begin","text":"<p><code>nosResult Begin(const char* name, nosCmd* outCmd)</code> Parameters: <code>name</code>: Debug name for the commands that will be recorded using this cmd. <code>outCmd</code>: Filled with the handle for a command buffer that can be used with other calls.</p>"},{"location":"Subsystems/nosVulkan/#end","title":"End","text":"<p><code>nosResult End(nosCmd cmd, nosBool forceSubmit);</code> Marks the end of command buffer's use. Parameters: <code>forceSubmit</code>: Submits the command buffer to the GPU. Recorded commands are not executed until the command buffer is submitted to the GPU, regular nodes in the node path can get away with not submitting the command buffer. Nodes that communicate between the CPU and the GPU or other graphics API's needs to submit the command buffer in appopriate points. Mind that submitting the command buffer has a significant performance hit. This does not wait for the GPU, refer to End2. Command buffers used outside of the Scheduler thread are submitted even if this parameter is false. </p>"},{"location":"Subsystems/nosVulkan/#end2","title":"End2","text":"<p><code>nosResult End2(nosCmd cmd, nosBool forceSubmit, nosGPUEvent* outEventHandle);</code> Marks the end of command buffer's use. Parameters: <code>forceSubmit</code>: Submits the command buffer to the GPU. Command buffers used outside of the Scheduler thread are submitted even if this parameter is false. Refer to End for more detailed information. <code>outEventHandle</code>: If not null, fills the value with an event that will be signalled when the GPU completes execution of the commands in the command buffer. Mind that this does not submits the command buffer to GPU unless <code>forceSubmit</code> is <code>true</code>, waiting it before the command buffer is submitted will result in a timeout or deadlock. Returned event must be waited at some point using WaitGpuEvent, unless the event results in a leak.</p> <p><code>nosResult Copy(nosCmd, const nosResourceShareInfo* src, const nosResourceShareInfo* dst, const char* benchmark);</code></p> <p><code>nosResult RunPass(nosCmd, const nosRunPassParams* params);</code></p> <p><code>nosResult RunPass2(nosCmd, const nosRunPass2Params* params);</code></p> <p><code>nosResult RunComputePass(nosCmd, const nosRunComputePassParams* params);</code></p> <p><code>nosResult Clear(nosCmd, const nosResourceShareInfo* texture, nosVec4 color);</code></p> <p><code>nosResult Download(nosCmd, const nosResourceShareInfo* texture, nosResourceShareInfo* outBuffer);</code></p> <p><code>nosResult ImageLoad(nosCmd, const void* buf, nosVec2u extent, nosFormat format, nosResourceShareInfo* inOut);</code></p> <p><code>nosResult CreateResource(nosResourceShareInfo* inout);</code></p> <p><code>nosResult ImportResource(nosResourceShareInfo* inout);</code></p> <p><code>nosResult DestroyResource(const nosResourceShareInfo* resource);</code></p> <p><code>nosResult ReloadShaders(nosName nodeName);</code></p> <p><code>uint8_t* Map(const nosResourceShareInfo* buffer);</code></p> <p><code>nosResult GetColorTexture(nosVec4 color, nosResourceShareInfo* out);</code></p> <p><code>nosResult GetStockTexture(nosResourceShareInfo* out);</code></p> <p><code>nosResult CreateSemaphore(uint64_t pid, uint64_t externalOSHandle, nosSemaphore* outSemaphore);</code></p> <p><code>nosResult DestroySemaphore(nosSemaphore semaphore);</code></p> <p><code>nosResult AddSignalSemaphoreToCmd(nosCmd cmd, nosSemaphore semaphore, uint64_t signalValue);</code></p> <p><code>nosResult AddWaitSemaphoreToCmd(nosCmd cmd, nosSemaphore semaphore, uint64_t waitValue);</code></p> <p><code>nosResult SignalSemaphore(nosSemaphore semaphore, uint64_t value);</code></p> <p><code>nosResult RegisterShaders(size_t count, nosShaderInfo* shaders);</code></p> <p><code>nosResult RegisterPasses(size_t count, nosPassInfo* passInfos);</code></p>"},{"location":"Subsystems/nosVulkan/#waitgpuevent","title":"WaitGpuEvent","text":"<p><code>nosResult WaitGpuEvent(nosGPUEvent* eventHandle, uint64_t timeoutNs);</code> Waits for the gpu to complete the work until the given event or timeout, then deletes the event. Parameters: <code>eventHandle</code>: Event handle to wait, will be set to null afterwards. <code>timeoutNs</code>: Timeout in nanoseconds, pass UINT64_T for max and 0 for deleting the event without any wait.</p>"}]}